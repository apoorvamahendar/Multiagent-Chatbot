{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a816fa1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import streamlit as st\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict, Annotated\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from tools import tool1_weather, tool2_stock, tool3_general_qa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c19b58d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "672478e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict, total=False):\n",
    "    messages: Annotated[list, \"shared\"]\n",
    "    chat_history: list  \n",
    "    weather_data: str\n",
    "    stock_data: str\n",
    "    final_answer: str\n",
    "    next_tools: list[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38dcfc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(api_key=os.getenv(\"GROQ_API_KEY\"), model=\"llama3-70b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5e4168",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 13:58:37.711 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:58:37.713 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "C:\\Users\\Mahendra\\AppData\\Local\\Temp\\ipykernel_17728\\1046608496.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  st.session_state.memory = ConversationBufferMemory(return_messages=True)\n",
      "2025-07-23 13:58:37.713 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:58:37.713 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 13:58:37.713 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "if \"memory\" not in st.session_state:\n",
    "    st.session_state.memory = ConversationBufferMemory(return_messages=True)\n",
    "\n",
    "memory = st.session_state.memory  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9451e48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast  \n",
    "\n",
    "def planner_node(state: AgentState) -> AgentState:\n",
    "    query = state[\"messages\"][-1].content.lower()\n",
    "\n",
    "    tool_prompt = f\"\"\"\n",
    "You are a tool selector for a multi-agent AI assistant.\n",
    "\n",
    "Your job is to return ONLY a Python list of tool names to use (in correct order). Do NOT explain, comment, or add anything else.\n",
    "\n",
    "Available tools:\n",
    "- \"weather_agent\": for weather, temperature, or forecast-related queries\n",
    "- \"stock_agent\": for stock prices, company tickers, or market-related questions\n",
    "- \"qa_agent\": always include this LAST for summarizing final answers\n",
    "\n",
    "User query:\n",
    "\"{query}\"\n",
    "\n",
    "Respond with a Python list of tool names. Example:\n",
    "[\"weather_agent\", \"stock_agent\", \"qa_agent\"]\n",
    "\"\"\"\n",
    "\n",
    "    raw_response = llm.invoke(tool_prompt).content.strip()\n",
    "    print(\"🧠 Tool planner raw response:\", raw_response)\n",
    "\n",
    "    # Safe parsing\n",
    "    try:\n",
    "        selected_tools = ast.literal_eval(raw_response)\n",
    "        if not isinstance(selected_tools, list):\n",
    "            raise ValueError(\"Not a valid list\")\n",
    "    except Exception as e:\n",
    "        print(\"❌ Failed to parse tools:\", e)\n",
    "        # Fallback to QA only (if LLM messes up)\n",
    "        selected_tools = [\"qa_agent\"]\n",
    "\n",
    "    # Ensure QA agent is last\n",
    "    if \"qa_agent\" not in selected_tools:\n",
    "        selected_tools.append(\"qa_agent\")\n",
    "\n",
    "    print(\"✅ Final selected tools:\", selected_tools)\n",
    "    return {**state, \"next_tools\": selected_tools}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af25ea4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router_fn(state: AgentState) -> str:\n",
    "    tools = state.get(\"next_tools\", [])\n",
    "    if tools:\n",
    "        return tools[0]  \n",
    "    return \"qa_agent\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01824dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "weather_agent = RunnableLambda(lambda state: {\n",
    "    **state,\n",
    "    \"weather_data\": tool1_weather.invoke(state[\"messages\"][-1].content),\n",
    "    \"next_tools\": state[\"next_tools\"][1:],\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3efcf5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_agent = RunnableLambda(lambda state: {\n",
    "    **state,\n",
    "    \"stock_data\": tool2_stock.invoke(state[\"messages\"][-1].content),\n",
    "    \"next_tools\": state[\"next_tools\"][1:],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1729119",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "def qa_agent_node(state: AgentState) -> AgentState:\n",
    "    user_input = state[\"messages\"][-1].content.lower()\n",
    "    past_messages = state.get(\"chat_history\", [])\n",
    "\n",
    "   \n",
    "    if \"summarize\" in user_input or \"summary\" in user_input:\n",
    "        filtered = [msg for msg in past_messages if \"summarize\" not in msg.content.lower()]\n",
    "        num_user = sum(isinstance(msg, HumanMessage) for msg in filtered)\n",
    "        num_bot = sum(isinstance(msg, AIMessage) for msg in filtered)\n",
    "\n",
    "        if num_user < 1 or num_bot < 1:\n",
    "            summary = \"There is not enough conversation to summarize yet.\"\n",
    "        else:\n",
    "            history_text = \"\\n\".join(\n",
    "                f\"{'User' if isinstance(msg, HumanMessage) else 'Bot'}: {msg.content}\"\n",
    "                for msg in filtered\n",
    "            )\n",
    "            # prompt = (\n",
    "            #     \"You are a helpful assistant. Summarize the following conversation:\\n\\n\"\n",
    "            #     f\"{history_text}\\n\\nWrite a clear and concise summary.\"\n",
    "            # )\n",
    "            # summary = llm.invoke(prompt).content.strip()\n",
    "            \n",
    "            prompt = (\n",
    "                f\"You are a helpful assistant. The user asked: \\\"{user_input}\\\"\\n\\n\"\n",
    "                f\"{context.strip()}\\n\\n\"\n",
    "                f\"⚠️ IMPORTANT: Do not reformat or alter the weather forecast output. \"\n",
    "                f\"Keep the exact structure and formatting as shown — especially dates like 'Wednesday, 24 July 2025'. \"\n",
    "                f\"Do not replace these with 'Day 1', 'Day 2', etc. Just return the full response exactly.\"\n",
    "            )\n",
    "\n",
    "\n",
    "            response = llm.invoke(prompt)\n",
    "\n",
    "        updated_history = past_messages + [AIMessage(content=summary)]\n",
    "        return {**state, \"final_answer\": summary, \"chat_history\": updated_history, \"next_tools\": []}\n",
    "\n",
    "    \n",
    "    context = \"\"\n",
    "    if state.get(\"weather_data\"):\n",
    "        context += f\"\\n**Weather Info:**\\n{state['weather_data']}\\n\"\n",
    "    if state.get(\"stock_data\"):\n",
    "        context += f\"\\n**Stock Info:**\\n{state['stock_data']}\\n\"\n",
    "\n",
    "    prompt = (\n",
    "        f\"You are a helpful assistant. The user asked: \\\"{user_input}\\\"\\n\\n\"\n",
    "        f\"{context.strip()}\\n\\nKeep it concise.\"\n",
    "    )\n",
    "    response = llm.invoke(prompt)\n",
    "    updated_history = past_messages + [HumanMessage(content=user_input), AIMessage(content=response.content)]\n",
    "\n",
    "    return {\n",
    "        **state,\n",
    "        \"final_answer\": response.content,\n",
    "        \"chat_history\": updated_history,\n",
    "        \"next_tools\": []\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf9968fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.set_entry_point(\"planner\")\n",
    "\n",
    "graph.add_node(\"planner\", planner_node)\n",
    "graph.add_node(\"weather_agent\", weather_agent)\n",
    "graph.add_node(\"stock_agent\", stock_agent)\n",
    "graph.add_node(\"qa_agent\", qa_agent_node)\n",
    "\n",
    "graph.add_conditional_edges(\"planner\", router_fn, {\n",
    "    \"weather_agent\": \"weather_agent\",\n",
    "    \"stock_agent\": \"stock_agent\",\n",
    "    \"qa_agent\": \"qa_agent\",\n",
    "})\n",
    "graph.add_conditional_edges(\"weather_agent\", router_fn, {\n",
    "    \"weather_agent\": \"weather_agent\",\n",
    "    \"stock_agent\": \"stock_agent\",\n",
    "    \"qa_agent\": \"qa_agent\",\n",
    "})\n",
    "graph.add_conditional_edges(\"stock_agent\", router_fn, {\n",
    "    \"weather_agent\": \"weather_agent\",\n",
    "    \"stock_agent\": \"stock_agent\",\n",
    "    \"qa_agent\": \"qa_agent\",\n",
    "})\n",
    "graph.add_edge(\"qa_agent\", END)\n",
    "\n",
    "multiagent_app = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7bad4756",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def invoke_multiagent(user_input: str) -> str:\n",
    "    # ✅ Add user input to memory\n",
    "    memory.chat_memory.add_user_message(user_input)\n",
    "\n",
    "    # ✅ Fetch full message history from memory\n",
    "    full_messages = memory.chat_memory.messages\n",
    "\n",
    "    # ✅ Create LangGraph-compatible state with full history\n",
    "    initial_state = {\n",
    "        \"messages\": full_messages,\n",
    "        \"chat_history\": full_messages \n",
    "    }\n",
    "\n",
    "    # ✅ Run LangGraph with full memory-aware context\n",
    "    result = multiagent_app.invoke(initial_state)\n",
    "\n",
    "    # ✅ Add final assistant reply to memory\n",
    "    memory.chat_memory.add_ai_message(result[\"final_answer\"])\n",
    "\n",
    "    return result[\"final_answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bce9f199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-23 14:01:25.559 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:25.577 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.198 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Mahendra\\AppData\\Roaming\\Python\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-07-23 14:01:28.198 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.209 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.221 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.223 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.227 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.228 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.229 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-07-23 14:01:28.231 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        import streamlit.web.bootstrap\n",
    "        IS_STREAMLIT = True\n",
    "    except ImportError:\n",
    "        IS_STREAMLIT = False\n",
    "\n",
    "    if IS_STREAMLIT or \"STREAMLIT_SERVER_HEADLESS\" in os.environ:\n",
    "        st.set_page_config(page_title=\"LangGraph Chatbot\", layout=\"centered\")\n",
    "        st.title(\"🧠 LangGraph Multi-Agent Chatbot\")\n",
    "        st.markdown(\"Ask about weather, stocks, or general questions!\")\n",
    "\n",
    "        if \"chat_history\" not in st.session_state:\n",
    "            st.session_state.chat_history = []\n",
    "\n",
    "        user_input = st.chat_input(\"Type your message...\")\n",
    "\n",
    "        if user_input:\n",
    "            st.session_state.chat_history.append((\"user\", user_input))\n",
    "            with st.spinner(\"🤔 Thinking...\"):\n",
    "                reply = invoke_multiagent(user_input)\n",
    "            st.session_state.chat_history.append((\"bot\", reply))\n",
    "\n",
    "        for role, message in st.session_state.chat_history:\n",
    "            with st.chat_message(role):\n",
    "                st.markdown(message)\n",
    "    else:\n",
    "        while True:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.strip().lower() in {\"exit\", \"quit\"}:\n",
    "                break\n",
    "            response = invoke_multiagent(user_input)\n",
    "            print(\"🤖 Bot:\", response)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
